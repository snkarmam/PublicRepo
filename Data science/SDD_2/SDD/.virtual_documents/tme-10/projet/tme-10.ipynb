




















# Importation de librairies standards:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline  

# un nouvel import utile pour la 3D:
from matplotlib import cm

# Les instructions suivantes sont TRES utiles pour recharger automatiquement 
# le code modifié dans les librairies externes
%load_ext autoreload
%autoreload 2

# Pour mesurer le temps
import time

# Importation de votre librairie iads:
# La ligne suivante permet de préciser le chemin d'accès à la librairie iads
import sys
sys.path.append('../')   # iads doit être dans le répertoire père du répertoire courant !

# Importation de la librairie iads
import iads as iads

# importation de Classifiers
from iads import Classifiers as classif

# importation de utils
from iads import utils as ut

# importation de evaluation
from iads import evaluation as ev

# importation de Clustering
from iads import Clustering as clust

from iads import arbre as ab

# commande TRES utile pour recharger automatiquement le code que vous modifiez dans les modules
%load_ext autoreload
%autoreload 2





pip install -U ucimlrepo





from ucimlrepo import fetch_ucirepo,list_available_datasets

# check which datasets can be imported
#list_available_datasets()

# import dataset
pen_dataset = fetch_ucirepo(id=81)

# access data
X = pen_dataset.data.features
y = pen_dataset.data.targets

# access metadata
print(pen_dataset.metadata.uci_id)
print(pen_dataset.metadata.num_instances)
print(pen_dataset.metadata.additional_info.summary)

# access variable info in tabular format
print(pen_dataset.variables)


X[0:10]


y[0:10]


np.unique(y.Class)











nb_lig,nb_col = X.shape
X_np = np.array(X)
Y_np = np.array([y["Class"][i] for i in range(nb_lig)])
Y_np





import matplotlib.pyplot as plt
for i in range(0,13,2):
    x0 = X.iloc[0][i]
    y0=X.iloc[0][i+1]
    x1 = X.iloc[0][i+2]
    y1 = X.iloc[0][i+3]
    plt.plot([x0,x1],[y0,y1])
plt.show()








np.random.seed(42)   # on prend 42 comme graine
k=5
knn = classif.ClassifierKNN(16,5)
perf, taux_moyen, taux_ecart = ev.validation_croisee(knn,(X_np,Y_np),10) 

# Classification du dataset (contrôle de predict et score):
print("Classification KNN des exemples du dataset:")
print(f'Analyse perf: moyenne: {taux_moyen:0.4f}\tecart: {taux_ecart:0.4f}')









import random 
np.random.seed(42)   # on prend 42 comme graine


# Création d'un classifieur KNN de dimension 2:
KNN = classif.ClassifierKNN_MC(16,5,10)

# Par définition, ce classifieur n'a pas besoin d'entraînement
KNN.train(X_np,Y_np)

perf = KNN.accuracy(X_np, Y_np)

# Classification du dataset (contrôle de predict et score):
print("Classification KNN multiclass des exemples du dataset:")
# Affichage du taux de bonne classification    
perf_m, taux_moyen_m, taux_ecart_m = ev.validation_croisee(KNN, (X_np, Y_np), 10)
print(f'Analyse perf: moyenne: {taux_moyen_m:0.4f}\tecart: {taux_ecart_m:0.4f}\t accuracy :{perf:0.4f}')





input_dim = 16
eps = 1e5 
cl_biais = classif.ClassifierPerceptron(input_dim, learning_rate=0.01, init=True)
cl_mult_biais=classif.ClassifierMultiOAA(cl_biais)

cl_mult_biais.train(X_np, Y_np)

acc_perf = cl_mult_biais.accuracy(X_np, Y_np)
perf, taux_moyen, taux_ecart = ev.validation_croisee(cl_biais, (X_np, Y_np), 10)

perf_mt, taux_moyen_mt, taux_ecart_mt = ev.validation_croisee(cl_mult_biais, (X_np, Y_np), 10)


# Classification du dataset (contrôle de predict et score):
print("Classification Perceptron des exemples du dataset:")
print(f'Analyse perf: moyenne: {taux_moyen:0.4f}\tecart: {taux_ecart:0.4f}\t accuracy :{acc_perf:0.4f}')
# Classification du dataset (contrôle de predict et score):
print("Classification MultiOAA des exemples du dataset:")
# Affichage du taux de bonne classification    
print("Taux de bonne classification sur le dataset: ", cl_mult_biais.accuracy(X_np,Y_np))
print(f'Analyse perf: moyenne: {taux_moyen_mt:0.4f}\tecart: {taux_ecart_mt:0.4f}\t accuracy :{acc_perf_mt:0.4f}')






x_noms = X.columns.tolist()

print("Noms des features: \n", x_noms)
print("Noms des labels: ", np.unique(Y_np))



import graphviz as gv
# Initialiation d'un arbre pour le dataset X:
arbre = classif.ClassifierArbreNumerique(len(x_noms), .0, x_noms)

# Construction de l'arbre de décision à partir du dataset X
arbre.train(X_np,Y_np)

# Construction de la représentation graphique (affichage)
graphe_arbre_chiffre = gv.Digraph(format='png')
arbre.affiche(graphe_arbre_chiffre)
graphe_arbre_chiffre


# mesure du taux de bonne classification
perf, taux_moyen, taux_ecart = ev.validation_croisee(arbre, (X_np, Y_np), 10)

print("Classification arbre numérique des exemples du dataset:")
print(f'Analyse perf: moyenne: {taux_moyen:0.4f}\tecart: {taux_ecart:0.4f}\t accuracy :{acc_perf:0.4f}')









